{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bsï¼” import BeautifulSoup\n",
    "import urllib.request\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image, ImageFilter\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape image urls from Pinterest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491\n"
     ]
    }
   ],
   "source": [
    "FILE_NAME = './pinterest-explorer.html'\n",
    "\n",
    "f = open(FILE_NAME, 'r')\n",
    "soup = BeautifulSoup(f.read(), 'html5lib')\n",
    "f.close()\n",
    "\n",
    "items = soup.findAll('div', {\"class\":\"Grid__Item\"})\n",
    "\n",
    "urls = []\n",
    "for item in items:\n",
    "    srcset = item.findAll('img')[0].attrs['srcset']\n",
    "    src = srcset.split('2x, ')[1]\n",
    "    src = src.replace(' 3x', '')\n",
    "    urls.append(src)\n",
    "    \n",
    "urls = list(set(urls))\n",
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/491\n",
      "100/491\n",
      "200/491\n",
      "300/491\n",
      "400/491\n"
     ]
    }
   ],
   "source": [
    "DEST_DIR = './images/'\n",
    "\n",
    "for i, url in enumerate(urls):\n",
    "    name = url.split('/')[-1]\n",
    "    if not os.path.exists(DEST_DIR + name):\n",
    "        try:\n",
    "            res = urllib.request.urlretrieve(url, DEST_DIR + name)\n",
    "        except UnicodeEncodeError:\n",
    "            continue\n",
    "\n",
    "    time.sleep(0.4)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(str(i) + '/' + str(len(urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_DIR     = './images/'\n",
    "OUT_DIR    = './resized/'\n",
    "MIN_LENGTH = 256\n",
    "DIFF       = 10\n",
    "\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "\n",
    "files = glob.glob(IN_DIR + '/*')\n",
    "\n",
    "for f in files:\n",
    "    name_arr = f.rsplit('/', 1)[1].split('.')\n",
    "    file_name, file_extension = name_arr[0], name_arr[1]\n",
    "\n",
    "    image = Image.open(f)\n",
    "\n",
    "    # Get dimensions\n",
    "    width, height = image.size\n",
    "    \n",
    "    if width < MIN_LENGTH or height < MIN_LENGTH:\n",
    "        continue\n",
    "    \n",
    "    index = 0\n",
    "    if width >= height:\n",
    "        resized_image = image.resize((int(MIN_LENGTH * width / height), MIN_LENGTH))\n",
    "        width, height = resized_image.size\n",
    "\n",
    "        for left in range(0, width - MIN_LENGTH, DIFF):\n",
    "            right = left + MIN_LENGTH\n",
    "            out_image = resized_image.crop((left, 0, right, MIN_LENGTH))\n",
    "            \n",
    "            out_path = OUT_DIR + file_name + '_' + str(index) + '.' + file_extension\n",
    "            out_image.save(out_path)\n",
    "            out_path = OUT_DIR + file_name + '_' + str(index) + '_T.' + file_extension\n",
    "            out_image.transpose(Image.FLIP_LEFT_RIGHT).save(out_path)\n",
    "            index += 1\n",
    "        \n",
    "    else:\n",
    "        resized_image = image.resize((int(MIN_LENGTH * width / height), MIN_LENGTH))\n",
    "        width, height = resized_image.size\n",
    "\n",
    "        for top in range(0, height - MIN_LENGTH, DIFF):\n",
    "            bottom = top + MIN_LENGTH\n",
    "            out_image = resized_image.crop((0, top, MIN_LENGTH, bottom))\n",
    "    \n",
    "            out_path = OUT_DIR + file_name + '_' + str(index) + '.' + file_extension\n",
    "            out_image.save(out_path)\n",
    "            out_path = OUT_DIR + file_name + '_' + str(index) + '_T.' + file_extension\n",
    "            out_image.transpose(Image.FLIP_LEFT_RIGHT).save(out_path)\n",
    "            index += 1            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_DIR  = './resized/'\n",
    "OUT_DIR = './line/'\n",
    "\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "    \n",
    "files = glob.glob(IN_DIR + '/*')\n",
    "\n",
    "for f in files:\n",
    "    file_path = f.rsplit('/', 1)[1]\n",
    "    image = cv2.imread(f, 1)\n",
    "    \n",
    "    ind = np.random.rand()\n",
    "    if ind < 0.3:\n",
    "        result = cv2.GaussianBlur(image, ksize=(3, 3), sigmaX=3)\n",
    "    elif ind < 0.6:\n",
    "        result = cv2.GaussianBlur(image, ksize=(5, 5), sigmaX=3)\n",
    "    elif ind < 0.9:\n",
    "        result = cv2.blur(image, ksize=(3, 3))\n",
    "    else:\n",
    "        result = cv2.blur(image, ksize=(5,5))\n",
    "\n",
    "    threshold1 = int(np.random.rand() * 30) + 1\n",
    "    threshold2 = int(np.random.rand() * 70) + 130\n",
    "    \n",
    "    result = cv2.Canny(result, threshold1, threshold2)\n",
    "    \n",
    "    row,col = result.shape\n",
    "    mean = 0\n",
    "    var = np.random.rand() * 0.2\n",
    "    sigma = var**0.5\n",
    "    gauss = np.random.normal(mean,sigma,(row,col))\n",
    "    gauss = gauss.reshape(row,col).astype(np.uint8)\n",
    "    result += gauss\n",
    "    \n",
    "    out_path = OUT_DIR + file_path\n",
    "    cv2.imwrite(out_path, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_SRC_DIR = './line/'\n",
    "B_SRC_DIR = './resized/'\n",
    "\n",
    "A_DST_DIR = './A/'\n",
    "B_DST_DIR = './B/'\n",
    "\n",
    "for root_dir in [A_DST_DIR, B_DST_DIR]:\n",
    "    \n",
    "    if not os.path.exists(root_dir):\n",
    "        os.makedirs(root_dir)\n",
    "        \n",
    "    for sub_dir in ['train', 'test', 'val']:\n",
    "        \n",
    "        if not os.path.exists(root_dir + sub_dir):\n",
    "            os.makedirs(root_dir + sub_dir)\n",
    "    \n",
    "files = glob.glob(A_SRC_DIR + '/*')\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "for a_src in files:\n",
    "    file_path = a_src.rsplit('/', 1)[1]\n",
    "    \n",
    "    b_src = B_SRC_DIR + file_path\n",
    "    \n",
    "    ind = int(np.random.rand(1) * 20)\n",
    "    directory = ''\n",
    "    if ind == 0:\n",
    "        directory = 'test'\n",
    "    elif ind == 1:\n",
    "        directory = 'val'\n",
    "    else:\n",
    "        directory = 'train'\n",
    "\n",
    "    shutil.copy2(a_src, A_DST_DIR + directory + '/' + file_path)\n",
    "    shutil.copy2(b_src, B_DST_DIR + directory + '/' + file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split = test, use 117/117 images\n",
      "split = test, number of images = 117\n",
      "split = train, use 2006/2006 images\n",
      "split = train, number of images = 2006\n",
      "split = val, use 97/97 images\n",
      "split = val, number of images = 97\n"
     ]
    }
   ],
   "source": [
    "from pdb import set_trace as st\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "A_DIR = './A/'\n",
    "B_DIR = './B/'\n",
    "AB_DIR = './AB/'\n",
    "\n",
    "splits = os.listdir(A_DIR)\n",
    "\n",
    "for sp in splits:\n",
    "    img_fold_A = os.path.join(A_DIR, sp)\n",
    "    img_fold_B = os.path.join(B_DIR, sp)\n",
    "    img_list = os.listdir(img_fold_A)\n",
    "\n",
    "    num_imgs = len(img_list)\n",
    "    print('split = %s, use %d/%d images' % (sp, num_imgs, len(img_list)))\n",
    "    img_fold_AB = os.path.join(AB_DIR, sp)\n",
    "    if not os.path.isdir(img_fold_AB):\n",
    "        os.makedirs(img_fold_AB)\n",
    "    print('split = %s, number of images = %d' % (sp, num_imgs))\n",
    "    for n in range(num_imgs):\n",
    "        name_A = img_list[n]\n",
    "        path_A = os.path.join(img_fold_A, name_A)\n",
    "        name_B = name_A\n",
    "        path_B = os.path.join(img_fold_B, name_B)\n",
    "        if os.path.isfile(path_A) and os.path.isfile(path_B):\n",
    "            name_AB = name_A\n",
    "            path_AB = os.path.join(img_fold_AB, name_AB)\n",
    "            im_A = cv2.imread(path_A, 1)\n",
    "            im_B = cv2.imread(path_B, 1)\n",
    "            im_AB = np.concatenate([im_A, im_B], 1)\n",
    "            cv2.imwrite(path_AB, im_AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
